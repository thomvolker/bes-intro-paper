---
title: "R-Script for 'Bayesian Evidence Synthesis for Informative Hypotheses: An introduction'"
author: "Irene Klugkist and Thom Volker"
date: "`r format(Sys.time(), '%B %d, %Y')`"
mainfont: Arial
fontsize: 12pt
urlcolor: blue
params:
  save: true
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    df_print: paged
    theme: paper
    highlight: pygments
    latexengine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load required packages

```{r, results=F, message=F, warning=F}
library(tidyverse)
extrafont::loadfonts(quiet=T)
```

# Plot prior and posterior beta distribution


With prior specification
$$
B(\alpha, \beta) = B(1,1),
$$
and posterior
$$
B(\alpha, \beta) = B(8, 4),
$$
corresponding to a sample of size $n = 10$ with $7$ successes and $3$ failures.

```{r}
beta_plot <- 
  ggplot() +
  geom_function(fun = dbeta,
                args = list(shape1 = 1, shape2 = 1),
                mapping = aes(linetype = "1")) +
  geom_function(fun = dbeta, 
                args = list(shape1 = 8, shape2 = 4),
                mapping = aes(linetype = "2")) +
  geom_vline(xintercept = 0.6, size = 0.3) +
  geom_point(aes(x = c(0.6, 0.6), 
                 y = c(dbeta(0.6, 1, 1), dbeta(0.6, 8, 4))), 
             size = 3) +
  xlab(expression(theta)) +
  ylab(expression(paste("P(", theta, " | n, x, ", alpha, ", ", beta, ")"))) +
  theme_classic() +
  scale_linetype_discrete(labels = c("Prior Beta(1,1)", "Posterior Beta(8,4)")) +
  theme(legend.position = c(0.15, 0.95),
        legend.title = element_blank(),
        legend.text  = element_text(family = "Times New Roman", size = 12),
        axis.text  = element_text(family = "Times New Roman"),
        axis.title = element_text(family = "Times New Roman")) +
  scale_x_continuous(breaks = 0:5*0.2,
                     limits = c(0,1)) +
  scale_y_continuous(breaks = 0:6*0.5)

beta_plot

if (params$save) {ggsave(filename = "Figures/betaplot.pdf", 
                         beta_plot, device = cairo_pdf, dpi = 1000)}
```

# Table 2 - Section 2.3

We kept the success probability fixed at 0.7, but increased the sample size of the individual study to show what happens with the combined *Bayesian Evidence Synthesis* Bayes Factor, when evaluating the informative hypothesis $H_i: \theta > 0.6$ against an uninformative, unconstrained hypothesis $H_u: \theta$, against its complement $H_c: \theta < 0.6$ and against a classical null hypothesis $H_0: \theta = 0.6$.

```{r}
n_rep <- c(10, 20, 40, 80, 100, 500, 1000)

BF_iu <- (1 - pbeta(0.6, 0.7 * n_rep + 1, 0.3 * n_rep + 1)) / 0.4
BF_ic <- BF_iu / (pbeta(0.6, 0.7 * n_rep + 1, 0.3 * n_rep + 1) / 0.6)
BF_i0 <- BF_iu / dbeta(0.6, 0.7 * n_rep + 1, 0.3 * n_rep + 1)

BFs <- cbind(BF_iu, BF_ic, BF_i0) %>% t()
colnames(BFs) <- as.character(n_rep)
round(BFs, 2) %>% knitr::kable()
```

# Plots section 3

## BES and BSU

The first three plots show what BES actually does, especially compared to BSU, when evaluating the informative hypothesis $H_i: \theta > 0.6$ against an uninformative, unconstrained hypothesis $H_u: \theta$, against its complement $H_c: \theta < 0.6$ and against a classical null hypothesis $H_0: \theta = 0.6$. These are showed first. Note that the effect size (i.e., the true success probability) equals $\Theta = 0.7$. We update the evidence using five "studies" each with the exact success probability $\Theta = 0.7$ in every sample, and a sample size of $n = 20$.

### BES versus BSU -- $BF_{i,u}$

The first plot shows what happens when using Bayesian Evidence Synthesis and Bayesian Sequential Updating when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus an unconstrained hypothesis $H_u: \theta$, when the observed success probability in every study is fixed at $\Theta = 0.7$.

```{r}
## number of studies
nstudies <- 1:5

## sample size per study
n <- 20

ntotal <- nstudies * n

## Bayesian sequential updating informative hypothesis (p > 0.6) 
## versus unconstrained hypothesis
bsu_iu_7 <- (1 - pbeta(0.6, 0.7 * ntotal + 1, 0.3 * ntotal + 1)) / 0.4

## Bayesian evidence synthesis of informative hypothesis (p > 0.6) versus
## the unconstrained hypothesis
bes_iu_7    <- bsu_iu_7[1] ^ {1:length(nstudies)}

## Collect the study information in a single tibble for plotting
collect <- function(studies, bsu, bes) {
  tibble(`Number of studies` = studies,
         `Bayesian Sequential Updating_PMP` = bsu / (1 + bsu),
         `Bayesian Evidence Synthesis_PMP` = bes / (1 + bes)) %>%
    pivot_longer(cols = -`Number of studies`,
                 names_to = c("Method", ".value"),
                 names_sep = "_")
}

plot.bsu.bes.pmp <- function(collection) {
  collection %>%
    ggplot(aes(x = `Number of studies`, y = PMP, linetype = Method)) +
    geom_line() +
    geom_point() +
    theme_classic() +
    theme(legend.position = c(0.2, 0.95),
          legend.title = element_blank(),
          legend.text  = element_text(family = "Times New Roman", size = 12),
          axis.text  = element_text(family = "Times New Roman"),
          axis.title = element_text(family = "Times New Roman")) +
    ylim(0,1)
}



bes_bsu_7_Hiu_pmp <- collect(nstudies, bsu_iu_7, bes_iu_7) %>%
  plot.bsu.bes.pmp() +
  ylab(expression(PMP["i,u"]))


bes_bsu_7_Hiu_pmp

if (params$save) ggsave(filename = "Figures/bes_bsu_7_Hiu_pmp.pdf", 
                        plot = bes_bsu_7_Hiu_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

### BES versus BSU -- $BF_{i,c}$

The second plot shows what happens when using Bayesian Evidence Synthesis and Bayesian Sequential Updating when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus its complement $H_c: \theta < 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.7$.

```{r}
## Plot Hic

## Bayesian sequential updating informative hypothesis (p > 0.6) 
## versus complement (p < 0.6)
bsu_ic_7 <- bsu_iu_7 / (pbeta(0.6, 0.7 * ntotal + 1, 0.3 * ntotal + 1) / 0.6)

## Bayesian evidence synthesis of informative hypothesis (p > 0.6) 
## versus its complement (p < 0.6)
bes_ic_7 <- bsu_ic_7[1] ^ {1:length(nstudies)}

bes_bsu_7_Hic_pmp <- collect(nstudies, bsu_ic_7, bes_ic_7) %>%
  plot.bsu.bes.pmp() +
  ylab(expression(PMP["i,c"]))

bes_bsu_7_Hic_pmp

## Save the plot

if (params$save) ggsave(filename = "Figures/bes_bsu_7_Hic_pmp.pdf", 
                        plot = bes_bsu_7_Hic_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```
### BES versus BSU -- $BF_{i,0}$

The third plot shows what happens when using Bayesian Evidence Synthesis and Bayesian Sequential Updating when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus a null hypothesis $H_0: \theta = 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.7$.

```{r}
bsu_i0_7 <- bsu_iu_7 / dbeta(0.6, 0.7 * ntotal + 1, 0.3 * ntotal + 1)
bes_i0_7 <- bsu_i0_7[1] ^ {1:length(nstudies)}


bes_bsu_7_Hi0_pmp <- collect(nstudies, bsu_i0_7, bes_i0_7) %>%
  plot.bsu.bes.pmp() +
  ylab(expression(PMP["i,0"]))

bes_bsu_7_Hi0_pmp

if (params$save) ggsave(filename = "Figures/bes_bsu_7_Hi0_pmp.pdf", 
                        plot = bes_bsu_7_Hi0_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

### BES versus BSU -- Combine plots

A combination of the plots can be made using `facet_grid`, which is a function from the `ggplot2` package. However, before we can do this, we have to combine the data that is previously created in a single `tibble`, with an appropriate label that is set to represent the hypotheses under consideration.

```{r}
## Combine the three datasets
bfs7 <- bind_rows(collect(nstudies, bsu_iu_7, bes_iu_7),
                  collect(nstudies, bsu_ic_7, bes_ic_7),
                  collect(nstudies, bsu_i0_7, bes_i0_7),
                  .id = "Hypothesis")

bes_bsu_7_pmp <- bfs7 %>%
  mutate(Hypothesis = recode_factor(Hypothesis, 
                                    `1` = paste(expression(italic(H)["i"]~vs.~italic(H)["u"])),
                                    `2` = paste(expression(italic(H)["i"]~vs.~italic(H)["c"])),
                                    `3` = paste(expression(italic(H)["i"]~vs.~italic(H)["0"])))) %>%
  plot.bsu.bes.pmp() +
  facet_grid(~Hypothesis, labeller = label_parsed) +
  ylab(expression(PMP)) +
  theme(legend.position = "bottom",
        strip.text.x = element_text(family = "Times New Roman"))

bes_bsu_7_pmp

if (params$save) ggsave(filename = "Figures/bes_bsu_7_pmp.pdf", 
                        plot = bes_bsu_7_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```


## The effect of different alternatives

### Effect size = 0.8 -- BSU

This plot shows what happens when using Bayesian Sequential Updating when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus the unconstrained hypothesis $H_u: \theta$, the complement $H_c: \theta < 0.6$ and the null hypothesis $H_0: \theta = 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.8$.

```{r}
collect.alternative <- function(studies, iu, ic, i0) {
  tibble(`Number of studies` = studies,
         `BF_iu` = iu,
         `BF_ic` = ic,
         `BF_i0` = i0,
         `PMP_iu` = iu / (1 + iu),
         `PMP_ic` = ic / (1 + ic),
         `PMP_i0` = i0 / (1 + i0)) %>%
    pivot_longer(cols = !`Number of studies`,
                 names_to = c(".value", "Alternative"),
                 names_sep = "_",
                 values_to = ".value") %>%
    mutate(Alternative = factor(Alternative,
                                levels = c("iu", "ic", "i0"),
                                labels = c(paste(expression(italic(H)["i"]~vs.~italic(H)["u"])),
                                           paste(expression(italic(H)["i"]~vs.~italic(H)["c"])),
                                           paste(expression(italic(H)["i"]~vs.~italic(H)["0"]))),
                                ordered = TRUE))
}

plot.bf.alternative.pmp <- function(collection, mapping) {
    collection %>%
    ggplot(mapping = mapping) +
    geom_line() +
    geom_point() +
    theme_classic() +
    ylab(expression(PMP)) +
    ylim(0,1) +
    theme(legend.position = c(0.1, 0.9),
          legend.title = element_blank(),
          legend.text  = element_text(family = "Times New Roman", size = 12),
          axis.text  = element_text(family = "Times New Roman"),
          axis.title = element_text(family = "Times New Roman"))
}

bsu_iu_8 <- (1 - pbeta(0.6, 0.8 * ntotal + 1, 0.2 * ntotal + 1)) / 0.4
bes_iu_8 <- bsu_iu_8[1] ^ {1:length(nstudies)}

bsu_ic_8 <- bsu_iu_8 / (pbeta(0.6, 0.8 * ntotal + 1, 0.2 * ntotal + 1) / 0.6)
bes_ic_8 <- bsu_ic_8[1] ^ {1:length(nstudies)}

bsu_i0_8    <- bsu_iu_8 / dbeta(0.6, 0.8 * ntotal + 1, 0.2 * ntotal + 1)
bes_i0_8    <- bsu_i0_8[1] ^ {1:length(nstudies)}




bsu_8_pmp <- collect.alternative(nstudies, bsu_iu_8, bsu_ic_8, bsu_i0_8) %>%
  plot.bf.alternative.pmp(mapping = aes(x = `Number of studies`, 
                                    y = PMP, 
                                    linetype = Alternative)) +
  scale_linetype_manual(values = c(1,2,3),
                        labels = scales::parse_format()) +
  theme(legend.position = "bottom")

bsu_8_pmp

if (params$save) ggsave(filename = "Figures/bsu_8_pmp.pdf", 
                        plot = bsu_8_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

### Effect size = 0.8 -- BES

This plot shows what happens when using Bayesian Evidence Synthesis when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus the unconstrained hypothesis $H_u: \theta$, the complement $H_c: \theta < 0.6$ and the null hypothesis $H_0: \theta = 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.8$.

```{r}
bes_8_pmp <- collect.alternative(nstudies, bes_iu_8, bes_ic_8, bes_i0_8) %>%
  plot.bf.alternative.pmp(mapping = aes(x = `Number of studies`, 
                                    y = PMP, 
                                    linetype = Alternative)) +
  scale_linetype_manual(values = c(1,2,3),
                        labels = scales::parse_format()) +
  theme(legend.position = "bottom")


bes_8_pmp

if (params$save) ggsave(filename = "Figures/bes_8_pmp.pdf", 
                        plot = bes_8_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

### Effect size = 0.6 -- BSU

This plot shows what happens when using Bayesian Sequential Updating when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus the unconstrained hypothesis $H_u: \theta$, the complement $H_c: \theta < 0.6$ and the null hypothesis $H_0: \theta = 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.6$.

```{r}
bsu_iu_6 <- (1 - pbeta(0.6, 0.6 * ntotal + 1, 0.4 * ntotal + 1)) / 0.4
bes_iu_6 <- bsu_iu_6[1] ^ {1:length(nstudies)}

bsu_ic_6 <- bsu_iu_6 / (pbeta(0.6, 0.6 * ntotal + 1, 0.4 * ntotal + 1) / 0.6)
bes_ic_6 <- bsu_ic_6[1] ^ {1:length(nstudies)}

bsu_i0_6 <- bsu_iu_6 / dbeta(0.6, 0.6 * ntotal + 1, 0.4 * ntotal + 1)
bes_i0_6 <- bsu_i0_6[1] ^ {1:length(nstudies)}


bsu_6_pmp <- collect.alternative(nstudies, bsu_iu_6, bsu_ic_6, bsu_i0_6) %>%
  plot.bf.alternative.pmp(mapping = aes(x = `Number of studies`, 
                                    y = PMP, 
                                    linetype = Alternative)) +
  scale_linetype_manual(values = c(1,2,3),
                        labels = scales::parse_format()) +
  theme(legend.position = "bottom")

bsu_6_pmp

if (params$save) ggsave(filename = "Figures/bsu_6_pmp.pdf", 
                        plot = bsu_6_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

### Effect size = 0.6 -- BES

This plot shows what happens when using Bayesian Evidence Synthesis when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus the unconstrained hypothesis $H_u: \theta$, the complement $H_c: \theta < 0.6$ and the null hypothesis $H_0: \theta = 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.6$.

```{r}
bes_6_pmp <- collect.alternative(nstudies, bes_iu_6, bes_ic_6, bes_i0_6) %>%
  plot.bf.alternative.pmp(mapping = aes(x = `Number of studies`, 
                                    y = PMP, 
                                    linetype = Alternative)) +
  scale_linetype_manual(values = c(1,2,3),
                        labels = scales::parse_format()) +
  theme(legend.position = "bottom")

bes_6_pmp

if (params$save) ggsave(filename = "Figures/bes_6_pmp.pdf", 
                        plot = bes_6_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

### Effect size = 0.4 -- BSU

This plot shows what happens when using Bayesian Sequential Updating when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus the unconstrained hypothesis $H_u: \theta$, the complement $H_c: \theta < 0.6$ and the null hypothesis $H_0: \theta = 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.4$.

```{r}
bsu_iu_4 <- (1 - pbeta(0.6, 0.4 * ntotal + 1, 0.6 * ntotal + 1)) / 0.4
bes_iu_4 <- bsu_iu_4[1] ^ {1:length(nstudies)}

bsu_ic_4 <- bsu_iu_4 / (pbeta(0.6, 0.4 * ntotal + 1, 0.6 * ntotal + 1) / 0.6)
bes_ic_4 <- bsu_ic_4[1] ^ {1:length(nstudies)}

bsu_i0_4 <- bsu_iu_4 / dbeta(0.6, 0.4 * ntotal + 1, 0.6 * ntotal + 1)
bes_i0_4 <- bsu_i0_4[1] ^ {1:length(nstudies)}


bsu_4_pmp <- collect.alternative(nstudies, bsu_iu_4, bsu_ic_4, bsu_i0_4) %>%
  plot.bf.alternative.pmp(mapping = aes(x = `Number of studies`, 
                                    y = PMP, 
                                    linetype = Alternative)) +
  scale_linetype_manual(values = c(1,2,3),
                        labels = scales::parse_format()) +
  theme(legend.position = "bottom")

bsu_4_pmp

if (params$save) ggsave(filename = "Figures/bsu_4_pmp.pdf", 
                        plot = bsu_4_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

### Effect size = 0.4 -- BES

This plot shows what happens when using Bayesian Evidence Synthesis when evaluating the informative hypothesis $H_i: \theta > 0.6$ versus the unconstrained hypothesis $H_u: \theta$, the complement $H_c: \theta < 0.6$ and the null hypothesis $H_0: \theta = 0.6$, when the observed success probability in every study is fixed at $\Theta = 0.4$.

```{r}
bes_4_pmp <- collect.alternative(nstudies, bes_iu_4, bes_ic_4, bes_i0_4) %>%
  plot.bf.alternative.pmp(mapping = aes(x = `Number of studies`, 
                                    y = PMP, 
                                    linetype = Alternative)) +
  scale_linetype_manual(values = c(1,2,3),
                        labels = scales::parse_format()) +
  theme(legend.position = "bottom")

bes_4_pmp

if (params$save) ggsave(filename = "Figures/bes_4_pmp.pdf", 
                        plot = bes_4_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```

```{r, fig.width=8, fig.height=7}
dat <- bind_rows(
  bind_rows(collect.alternative(nstudies, bes_iu_8, bes_ic_8, bes_i0_8),
            collect.alternative(nstudies, bes_iu_6, bes_ic_6, bes_i0_6),
            collect.alternative(nstudies, bes_iu_4, bes_ic_4, bes_i0_4),
            .id = "Theta"),
  bind_rows(collect.alternative(nstudies, bsu_iu_8, bsu_ic_8, bsu_i0_8),
            collect.alternative(nstudies, bsu_iu_6, bsu_ic_6, bsu_i0_6),
            collect.alternative(nstudies, bsu_iu_4, bsu_ic_4, bsu_i0_4),
            .id = "Theta"),
  .id = "Aggregation")

dat

bes_bsu_pmp <- dat %>%
  mutate(Aggregation = recode_factor(Aggregation,
                                     `1` = "Bayesian Evidence Synthesis",
                                     `2` = "Bayesian Sequential Updating"),
         Theta       = recode_factor(Theta,
                                     `1` = paste(expression(theta==0.8)),
                                     `2` = paste(expression(theta==0.6)),
                                     `3` = paste(expression(theta==0.4)))) %>%
  plot.bf.alternative.pmp(mapping = aes(x = `Number of studies`, 
                                    y = PMP, 
                                    linetype = Aggregation)) +
  facet_grid(Theta ~ Alternative, 
             labeller = label_parsed) +
  theme(strip.text.x = element_text(family = "Times New Roman"),
        strip.text.y = element_text(family = "Times New Roman"),
        legend.position = "bottom",
        legend.background = element_rect(fill = "transparent"),
        legend.title = element_blank()) #+
  #geom_hline(yintercept = c(-3:3 * 5), colour = "grey", size = 0.1)

bes_bsu_pmp

if (params$save) ggsave(filename = "Figures/bes_bsu_pmp.pdf", 
                        plot = bes_bsu_pmp, 
                        device = cairo_pdf, 
                        dpi = 1000)
```


# Small simulation section 4

First, we set the seed for reproducibility of our results and load the required packages.

```{r, message = FALSE}
## Set seed 
set.seed(123)

# Load packages
library(tidyverse)
library(magrittr)
library(furrr)
library(BFpack)
library(Rcpp)
library(RcppArmadillo)
# devtools::build("DataCpp")
# devtools::install("DataCpp")
library(DataCpp)
```

Then, we load the required functions to generate the simulated data.

```{r}
source("functions.R")
```

We also specify parallel processing to speed up the simulation, and specify the future seed (also for reproducibility).

```{r}
## Parallel processing
plan(multisession)

## Parallel seed
options <- furrr_options(seed = TRUE)
```

## Simulation 1

In simulation 1, we generate data from a normal OLS regression model, a logit regression model and a probit regression model, according to fixed effect sizes ($R^2 \in \{0.02, 0.09, 0.25\}$, and three regression coefficients that are tapering in size (e.g., $\beta_2 = 2\beta_1$ and $\beta_3 = 3\beta_1$), with a common correlation between predictors of $\rho = 0.3$. Sample sizes are specified as $n \in \{`r 25 * 2^{0:5}`\}$.

We run our simulations for 1000 iterations. 

```{r sim-specs}
################################################################################
## Specify simulation conditions
################################################################################

## Number of simulations 
nsim <- 1000

## Sample sizes
n <- 50 * 2^{0:4}

## Models
models <- c("normal", "logit", "probit")

## r2 of the regression model
r2 <- c(.02, .09, .25)

## Specify relative importance of the regression coefficients
ratio_beta <- c(1,1,1,2,3)

## Specify the bivariate correlations between predictors
pcor <- c(0.3)
```

To test whether the simulated data sets agree with our specifications, we test the specifications for all three different data generating models.

```{r test-specs}

gen_dat(0.02, 
        coefs(0.02, ratio_beta, cormat(pcor, length(ratio_beta)), "normal"),
        cormat(pcor, length(ratio_beta)),
        100000,
        "normal") %$%
  lm(Y ~ V1 + V2 + V3 + V4 + V5) %>%
  summary()

coefs(0.02, ratio_beta, cormat(pcor, length(ratio_beta)), "normal")

gen_dat(0.09, 
        coefs(0.09, ratio_beta, cormat(pcor, length(ratio_beta)), "logit"),
        cormat(pcor, length(ratio_beta)),
        100000,
        "logit") %$%
  glm(Y ~ V1 + V2 + V3 + V4 + V5, family = binomial(link = "logit")) %T>%
  {performance::r2_mckelvey(.) %>% print()} %>%
  summary()

coefs(0.09, ratio_beta, cormat(pcor, length(ratio_beta)), "logit")

gen_dat(0.25, 
        coefs(0.25, ratio_beta, cormat(pcor, length(ratio_beta)), "probit"),
        cormat(pcor, length(ratio_beta)),
        100000,
        "probit") %$%
  glm(Y ~ V1 + V2 + V3 + V4 + V5, family = binomial(link = "probit")) %T>%
  {performance::r2_mckelvey(.) %>% print()} %>%
  summary()

coefs(0.25, ratio_beta, cormat(pcor, length(ratio_beta)), "probit")
```

```{r}
library(xtable)
table_coefs <- function(R2, models, ratio, rho) {
  coef <- coefs(R2, ratio, rho, models) %>% sprintf(fmt = "%.3f") %>% t %>% as_tibble
  coef
}


betas <- expand_grid(r2, models) %>%
  mutate(coefs = map2(r2, models, 
                      ~table_coefs(.x, 
                                   .y, 
                                   ratio_beta, 
                                   cormat(pcor, length(ratio_beta))))) %>%
  unnest(cols = c(coefs)) %>%
  mutate(V0 = rep(" ", nrow(.))) %>%
  pivot_wider(names_from = models, 
              values_from = c("V0", "V1", "V2", "V3", "V4", "V5")) %>%
  mutate(r2 = as.character(r2)) %>%
  select(r2, 
         map(paste0(c("normal", "logit", "probit")), 
             ~paste0("V", c(0, 1, 4, 5), "_", .x)) %>% unlist())

beta_names <- c(" ", rep(c(" ", 
                           "$\\beta_{1, 2, 3}$",
                           "$\\beta_4$",
                           "$\\beta_5$"), 3)) %>%
  t %>%
  as_tibble

names(beta_names) <- colnames(betas)

betas <- bind_rows(beta_names, betas)

addtorow <- list()
addtorow$pos <- list(0)
addtorow$command <- c("$R^2$ & & \\multicolumn{3}{c}{OLS} & & \\multicolumn{3}{c}{Logistic} & & \\multicolumn{3}{c}{Probit} \\\\\n")
xtable(betas, 
       auto = TRUE,
       caption = c("Population-level regression coefficients for ordinary least squares (OLS), logistic and probit regression, given effect sizes of $R^2 \\in \\{0.02, 0.09, 0.25\\}$."),
       label = c("coefs")) %>%
  print(sanitize.text.function = function(x) {x},
        include.rownames = FALSE,
        include.colnames = FALSE,
        add.to.row = addtorow,
        booktabs = TRUE,
        hline.after = c(-1, 0, 1, nrow(.)),
        caption.placement = "top",
        table.placement = "t")
```


These tests do not indicate any misspecifications. 

```{r sim1, cache = TRUE}
sim1 <- 
  expand_grid(nsim = 1:nsim, 
              n = n, 
              pcor = pcor, 
              r2 = r2, 
              model = models) %>%
  mutate(rho   = map(pcor, ~cormat(.x, length(ratio_beta))),
         betas = pmap(list(r2, rho, model),                   # calculate regression
                      function(r2, rho, model) {              # coefficients given
                        coefs(r2, ratio_beta, rho, model)     # model specifications
                      }),
         fit = future_pmap(list(r2, betas, rho, n, model), 
                           function(r2, betas, rho, n, model) {
                             data_and_model(r2 = r2,
                                            betas = betas,
                                            rho = rho,
                                            n = n, 
                                            model = model,
                                            formula = Y ~ V1 + V2 + V3 + V4 + V5,
                                            hypothesis = "V3 < V4 < V5")
         }, .options = options))

saveRDS(sim1, file = "simulation-results/sim1.rds")
```

```{r sim1-plot}
sim1_plot_box <- sim1 %>%
  mutate(bf_iu = map_dbl(fit, ~.x[1,7]),
         bf_cu = map_dbl(fit, ~.x[2,7]),
         bf_ic = bf_iu / bf_cu) %>%
  group_by(nsim, n, r2) %>%
  summarize(across(.cols = starts_with("bf_"), .fns = ~prod(.x))) %>%
  mutate(pmp_iu = bf_iu / (bf_iu + 1),
         pmp_ic = bf_iu / (bf_iu + bf_cu),
         r2 = paste0("R^2: ", r2)) %>%
  ggplot(aes(x = as.factor(n), y = pmp_ic)) +
  geom_boxplot(fill = "black", alpha = 0.1) +
  facet_wrap(~r2, labeller = label_parsed) +
  theme_classic() +
  labs(y = expression(PMP["i,c"]),
       x = "Sample size") +
  theme(text = element_text(family = "Times New Roman")) +
  ylim(0,1)

sim1_plot_box

sim1_sep_plot_box <- sim1 %>%
  mutate(bf_iu = map_dbl(fit, ~.x[1,7]),
         bf_cu = map_dbl(fit, ~.x[2,7]),
         bf_ic = bf_iu / bf_cu,
         pmp_iu = bf_iu / (bf_iu + 1),
         pmp_ic = bf_iu / (bf_iu + bf_cu),
         r2 = paste0("R^2: ", r2),
         model = factor(model,
                        levels = c("normal", "logit", "probit"),
                        labels = c("OLS", "Logistic", "Probit"))) %>%
  ggplot(aes(x = as.factor(n), y = pmp_ic)) +
  geom_boxplot(fill = "black", alpha = 0.1) +
  facet_wrap(model~r2, labeller = label_parsed) +
  theme_classic() +
  labs(y = expression(PMP["i,c"]),
       x = "Sample size") +
  theme(text = element_text(family = "Times New Roman")) +
  ylim(0,1)

sim1_sep_plot_box

if (params$save) ggsave(filename = "Figures/sim1_box.pdf", 
                        plot = sim1_plot_box, 
                        device = cairo_pdf, 
                        dpi = 1000,
                        height = 3)

if (params$save) ggsave(filename = "Figures/sim1_sep_box.pdf",
                        plot = sim1_sep_plot_box,
                        device = cairo_pdf,
                        dpi = 1000,
                        height = 7)
```


## Simulation 2

In simulation 2, we build on simulation 1, in the sense that we use the same statistical models. However, now we also vary the operationalization of the independent variables. Specifically, in the linear model data, we consider three continuous predictors of equal size, that are all expected to have a positive effect on the outcome $Y$. In the logit simulations, we combine the three variables into a single continuous variable by taking the average of these three variables, considering it as a scale score, while in the probit simulations, we break up the single continuous measure into three categories, using probit regression with dummy variables. 

```{r sim2, cache = TRUE}
sim2_normal <- 
  expand_grid(nsim = 1:nsim,
              n = n,
              pcor = pcor,
              r2 = r2,
              model = "normal") %>%
  mutate(rho   = map(pcor, ~cormat(.x, length(ratio_beta))),
         betas = pmap(list(r2, rho, model),                   # calculate regression
                      function(r2, rho, model) {              # coefficients given
                        coefs(r2, ratio_beta, rho, model)     # model specifications
                      }),
         fit = future_pmap(list(r2, betas, rho, n, model), 
                           function(r2, betas, rho, n, model) {
                             data_and_model(r2 = r2,
                                            betas = betas,
                                            rho = rho,
                                            n = n, 
                                            model = model,
                                            formula = Y ~ V1 + V2 + V3 + V4 + V5,
                                            hypothesis = "V1 > 0 & V2 > 0 & V3 > 0")
         }, .options = options))

sim2_logit <- 
  expand_grid(nsim = 1:nsim,
              n = n,
              pcor = pcor,
              r2 = r2,
              model = "logit") %>%
  mutate(rho   = map(pcor, ~cormat(.x, length(ratio_beta))),
         betas = pmap(list(r2, rho, model),                   # calculate regression
                      function(r2, rho, model) {              # coefficients given
                        coefs(r2, ratio_beta, rho, model)     # model specifications
                      }),
         fit = future_pmap(list(r2, betas, rho, n, model), 
                           function(r2, betas, rho, n, model) {
                             data_and_model(r2 = r2,
                                            betas = betas,
                                            rho = rho,
                                            n = n, 
                                            model = model,
                                            mutate_args = quos(Vcomb = (V1 + V2 + V3)/3),
                                            formula = Y ~ Vcomb + V4 + V5,
                                            hypothesis = "Vcomb > 0")
         }, .options = options))


sim2_probit <- 
  expand_grid(nsim = 1:nsim,
              n = n,
              pcor = pcor,
              r2 = r2,
              model = "probit") %>%
  mutate(rho   = map(pcor, ~cormat(.x, length(ratio_beta))),
         betas = pmap(list(r2, rho, model),                   # calculate regression
                      function(r2, rho, model) {              # coefficients given
                        coefs(r2, ratio_beta, rho, model)     # model specifications
                      }),
         fit = future_pmap(list(r2, betas, rho, n, model), 
                           function(r2, betas, rho, n, model) {
                             data_and_model(r2 = r2,
                                            betas = betas,
                                            rho = rho,
                                            n = n, 
                                            model = model,
                                            mutate_args = quos(Dummy = cut((V1 + V2 + V3)/3,
                                                                           3, labels = 1:3)),
                                            formula = Y ~ Dummy - 1 + V4 + V5,
                                            hypothesis = "Dummy1 < Dummy2 < Dummy3")
         }, .options = options))

sim2 <- bind_rows(sim2_normal, sim2_logit, sim2_probit)

saveRDS(sim2, file = "simulation-results/sim2.rds")
```

```{r sim2-plot}
sim2_plot_box <- sim2 %>%
  mutate(bf_iu = map_dbl(fit, ~.x[1,7]),
         bf_cu = map_dbl(fit, ~.x[2,7]),
         bf_ic = bf_iu / bf_cu) %>%
  group_by(nsim, n, r2) %>%
  summarize(across(.cols = starts_with("bf_"), .fns = ~prod(.x))) %>%
  mutate(pmp_iu = bf_iu / (bf_iu + 1),
         pmp_ic = bf_iu / (bf_iu + bf_cu),
         r2 = paste0("R^2: ", r2)) %>%
  ggplot(aes(x = as.factor(n), y = pmp_ic)) +
  geom_boxplot(fill = "black", alpha = 0.1) +
  facet_wrap(~r2, labeller = label_parsed) +
  theme_classic() +
  labs(y = expression(PMP["i,c"]),
       x = "Sample size") +
  theme(text = element_text(family = "Times New Roman")) +
  ylim(0,1)

sim2_plot_box

sim2_sep_plot_box <- sim2 %>%
  mutate(bf_iu = map_dbl(fit, ~.x[1,7]),
         bf_cu = map_dbl(fit, ~.x[2,7]),
         bf_ic = bf_iu / bf_cu,
         pmp_iu = bf_iu / (bf_iu + 1),
         pmp_ic = bf_iu / (bf_iu + bf_cu),
         r2 = paste0("R^2: ", r2),
         model = factor(model,
                        levels = c("normal", "logit", "probit"),
                        labels = c("OLS", "Logistic", "Probit"))) %>%
  ggplot(aes(x = as.factor(n), y = pmp_ic)) +
  geom_boxplot(fill = "black", alpha = 0.1) +
  facet_wrap(model~r2, labeller = label_parsed) +
  theme_classic() +
  labs(y = expression(PMP["i,c"]),
       x = "Sample size") +
  theme(text = element_text(family = "Times New Roman")) +
  ylim(0,1)

sim2_sep_plot_box

sim12 <- bind_rows(sim1, sim2, .id = "Simulation") %>%
  mutate(r2 = paste0("$R^2 = ", r2, "$"),
         bf_iu = map_dbl(fit, ~.x[1,7]),
         bf_cu = map_dbl(fit, ~.x[2,7]),
         bf_ic = bf_iu / bf_cu)

summ_sim12 <- sim12 %>%
  group_by(Simulation, nsim, n, r2) %>%
  summarize(across(.cols = starts_with("bf_"), .fns = ~prod(.x))) %>%
  mutate(model = "Aggregated")

full_join(sim12, summ_sim12) %>%
  ungroup() %>%
  filter(r2 == "$R^2 = 0.02$" | r2 == "$R^2 = 0.25$",
         n %in% c(50, 200, 800)) %>%
  mutate(pmp_iu = bf_iu / (bf_iu + 1),
         pmp_ic = bf_iu / (bf_iu + bf_cu),
         model = factor(model,
                        levels = c("normal", "logit", "probit", "Aggregated"),
                        labels = c("OLS", "Logistic", "Probit", "Aggregated")),
         `Sample size` = n) %>%
  group_by(Simulation, r2, `Sample size`, model) %>%
  summarize(PMP_median = median(pmp_ic)) %>%
  pivot_wider(names_from = model, values_from = PMP_median) %>%
  xtable::xtable()


if (params$save) ggsave(filename = "Figures/sim2_box.pdf", 
                        plot = sim2_plot_box, 
                        device = cairo_pdf, 
                        dpi = 1000,
                        height = 3)

if (params$save) ggsave(filename = "Figures/sim2_sep_box.pdf", 
                        plot = sim2_sep_plot_box, 
                        device = cairo_pdf, 
                        dpi = 1000,
                        height = 7)
```

# Session details

```{r}
sessionInfo()
```

--- END OF DOCUMENT ---
